% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Layers.R
\name{LBBNN_Conv2d}
\alias{LBBNN_Conv2d}
\title{Class to generate an LBBNN convolutional layer}
\usage{
LBBNN_Conv2d(
  in_channels,
  out_channels,
  kernel_size,
  prior_inclusion,
  standard_prior,
  density_init,
  flow = FALSE,
  num_transforms = 2,
  hidden_dims = c(200, 200),
  device = "cpu"
)
}
\arguments{
\item{in_channels}{number of input channels.}

\item{out_channels}{number of output channels.}

\item{kernel_size}{Size of the convolving kernel.}

\item{prior_inclusion}{Prior inclusion probability for each weight.}

\item{standard_prior}{Prior standard deviation for each weight and bias.}

\item{density_init}{A vector of size two c(lower,upper) used to initialize the inclusion parameters.}

\item{flow}{determines whether normalizing flow should be used. TRUE or FALSE}

\item{num_transforms}{Number of transformations for the flow. Default is 2.}

\item{hidden_dims}{Dimension of the hidden layer(s) in the neural networks of the RNVP transform.}

\item{device}{The device to be used. Default is CPU.}
}
\description{
Includes function for forward pass, where one can
either use the full model, or the medium probability model (MPM).
Also contains method to initialize parameters and compute KL-divergence.
}
\examples{
if (requireNamespace("torch", quietly=TRUE)) torch::install_torch()
layer <- LBBNN_Conv2d(in_channels = 1,out_channels = 32,kernel_size = c(3,3),
prior_inclusion = 0.2,standard_prior = 1,density_init = c(-10,10),device = 'cpu')
x <-torch::torch_randn(100,1,28,28)
out <-layer(x)
print(dim(out))
}
